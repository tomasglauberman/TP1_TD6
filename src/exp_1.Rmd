---
title: "Experimento 1"
author: "Juan Silvestri"
date: "`r Sys.Date()`"
output: pdf_document
---

Se realizó un experimento en el que se analiza el impacto que tienen los datos faltantes en un dataset para un modelo de Árbol de decisión. Para ello, se entrenaron múltiples modelos para cada uno de los datasets, lo que nos permite estimar y evaluar la performance.

Las variables independientes del experimento son:

-   Profundidad del árbol (1-30)

-   Proporción de datos faltantes (0-1)

-   Valores faltantes imputados o no

En la siguiente figura se puede observar un resumen de los resultados.

```{r}
source("exp_1.R")
```

Se observa que a medida que aumenta la proporción de NAs la performance de los modelos disminuye. Por otro lado, en los datasets de Churn y Sleep Dissorder la performance sin imputar los datos faltantes es mejor que al imputar con la media. En el dataset de Heart Disease, la performance es similar.

En la mayoría de los casos, mayor profundidad en los árboles no parece mejorar la preformance. Esto ocurre porque los modelos son demasiado flexibles para la cantidad de datos o complejidad de las relaciones entre ellos, por lo que se ajustan por demás a los datos de entrenamiento (y su ruido) y luego su perormance no es muy buena con datos nuevos. Sin embargo, cuando la proporción de datos faltantes es muy alta, no se observa el fenómeno de overfitting. Suponemos que puede ocurrir debido a que no hay suficientes datos reales con los cuales se hace overfitting.
